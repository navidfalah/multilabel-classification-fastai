# -*- coding: utf-8 -*-
"""multi_label_classification_fastai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l3OkGyrI5HlOwi5o42m2gSa5XU5O-vvT
"""

#### pascal data set using for multi labelling

from fastai.vision.all import *

path = untar_data(URLs.PASCAL_2007)

path

df = pd.read_csv(path/'train.csv')
df.head()

df["labels"]

len(np.unique(df["labels"]))

df.shape

df.iloc[:, 0]

dblock = DataBlock()

dset = dblock.datasets(df)

dset.train[0]

dblock = DataBlock(get_x=lambda r: r["fname"], get_y = lambda r: r["labels"])
dset = dblock.datasets(df)
dset.train[0]

path_image = dset.train[0][0]
path_image

path_specific_img = Path(str(path)+"/"+"train/"+ path_image)
path_specific_img

from PIL import Image

img = Image.open(path_specific_img)
img

### as the lambda functions are not compatible with the serialization so we should define them as function s

def get_x(r): return path/'train'/r['fname']
def get_y(r): return r['labels'].split(' ')

dblock = DataBlock(get_x = get_x, get_y=get_y)
dset = dblock.datasets(df)
dset.train[1]

dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),
 get_x = get_x, get_y = get_y)
dsets = dblock.datasets(df)
dsets.train[0]

idxs = torch.where(dsets.train[0][1]==1.)[0]
dsets.train.vocab[idxs]

def splitter(df):
    train = df.index[~df['is_valid']].tolist()  # Rows where 'is_valid' is False
    valid = df.index[df['is_valid']].tolist()   # Rows where 'is_valid' is True
    return train, valid

dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),
 splitter=splitter,
 get_x=get_x,
 get_y=get_y)

dsets = dblock.datasets(df)
dsets.train[0]

### ensure that every image is in the same size
dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),
                   splitter=splitter,
                   get_x=get_x,
                   get_y=get_y,
                   item_tfms=RandomResizedCrop(128, min_scale=0.35))

dls = dblock.dataloaders(df)

dls.show_batch(nrows=1, ncols=4)

learn = cnn_learner(dls, resnet18)

x, y = dls.train.one_batch()
activs = learn.model(x)
activs.shape

activs[0]

def binary_cross_entropy(inputs, targets):
    inputs = inputs.sigmoid()
    return -torch.where(targets==1, inputs, 1-inputs).log().mean()

loss_func = nn.BCEWithLogitsLoss()

loss = loss_func(TensorBase(activs), TensorBase(y))
loss

def accuracy(inp, targ, axis=-1):
  pred = inp.argmax(dim=axis)
  return (pred==targ).float().mean()

def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):
  if sigmoid: inp = inp.sigmoid()
  return ((inp>thresh)==targ.bool()).float().mean()

learn = cnn_learner(dls, resnet18, metrics=partial(accuracy_multi, thresh=0.2))
learn.fine_tune(3, base_lr=3e-3, freeze_epochs=4)

learn.metrics = partial(accuracy_multi, thresh=0.2)

learn.validate()

preds, targs = learn.get_preds()

accuracy_multi(preds, targs, thresh=0.9, sigmoid=False)

xs = torch.linspace(0.05, 0.95, 29)
accs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs]
plt.plot(xs, accs)

